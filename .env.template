#############################
# Perplexica + MCP defaults #
#############################

# OpenAI-compatible LLM/embeddings used by Perplexica and the MCP wrapper
OPENAI_API_KEY=change_me
OPENAI_BASE_URL=https://api.openai.com/v1

# Ollama configuration (for local embeddings)
OLLAMA_BASE_URL=http://host.docker.internal:11434

# Optional: point Perplexica to an existing SearXNG (else defaults inside image)
SEARXNG_API_URL=http://perplexica:8080

# MCP wrapper -> talks to the Perplexica API inside docker-compose
PERPLEXICA_API_URL=http://perplexica:3000
MCP_PORT=8000
MCP_PROVIDER_NAME=OpenAI
MCP_LLM_MODEL=gpt-4o-mini
# Embedding model: using Ollama with embeddinggemma:300m-qat-q4_0
MCP_EMBED_PROVIDER_NAME=Ollama
MCP_EMBED_MODEL=embeddinggemma:300m-qat-q4_0
MCP_FOCUS_MODE=webSearch          # webSearch | academicSearch | writingAssistant | wolframAlphaSearch | youtubeSearch | redditSearch | habrSearch
MCP_OPTIMIZATION_MODE=speed    # balanced | speed
MCP_SYSTEM_INSTRUCTIONS=

# MCP transport: stdio (for local/Claude Desktop) or sse (for remote HTTP access)
MCP_TRANSPORT=sse
MCP_HOST=0.0.0.0
